% Want to distribute this code? Have other questions? -> sbowman@stanford.edu
function [ cost, grad, pred ] = ComputeLatticeCostAndGrad( theta, decoder, dataPoint, hyperParams )
% Compute cost, gradient, and predicted label for one example.

% Unpack theta
[classifierParameters, wordFeatures, compositionMatrices,...
    compositionMatrix, compositionBias, classifierExtraMatrix, ...
    classifierExtraBias] ...
    = stack2param(theta, decoder);

tree = dataPoint.tree;
trueSolution = dataPoint.solution;

% Make sure word features are current
tree.updateFeatures(wordFeatures, compositionMatrices, ...
        compositionMatrix, compositionBias, hyperParams.compNL);

features = tree.getFeatures();
       
% Run top layers forward
extraInputs = zeros(hyperParams.penultDim, hyperParams.topDepth);
extraInnerOutputs = zeros(hyperParams.penultDim, hyperParams.topDepth - 1);
extraInputs(:,1) = features;
for layer = 1:(hyperParams.topDepth - 1) 
    extraInnerOutputs(:,layer) = (classifierExtraMatrix(:,:,layer) ...
                                    * extraInputs(:,layer)) + ...
                                    classifierExtraBias(:,layer);
    extraInputs(:,layer + 1) = hyperParams.classNL(extraInnerOutputs(:,layer));
end

solutionProbs = ComputeSoftmaxProbabilities( ...
                    extraInputs(:,hyperParams.topDepth), classifierParameters);

% Compute cost
cost = Objective(trueSolution, solutionProbs);

% Produce gradient
if nargout > 1    
    [localSoftmaxGradient, softmaxDelta] = ...
        ComputeSoftmaxGradient (hyperParams, classifierParameters, ...
                                solutionProbs, trueSolution,...
                                extraInputs(:,hyperParams.topDepth));
    
    % Compute gradients for extra top layers
    [localExtraMatrixGradients, ...
          localExtraBiasGradients, extraDelta] = ...
          ComputeExtraClassifierGradients(hyperParams, ...
          classifierExtraMatrix, softmaxDelta, extraInputs, ...
          extraInnerOutputs);
  
    [ localWordFeatureGradients, ...
      localCompositionMatricesGradients, ...
      localCompositionMatrixGradients, ...
      localCompositionBiasGradients ] = ...
       tree.getGradient(extraDelta, wordFeatures, ...
                            compositionMatrices, compositionMatrix, ...
                            compositionBias, hyperParams.compNLDeriv);
                        
    % Pack up gradients.
    grad = param2stack(localSoftmaxGradient, ...
        localWordFeatureGradients, localCompositionMatricesGradients, ...
        localCompositionMatrixGradients, localCompositionBiasGradients, ...
        localExtraMatrixGradients, localExtraBiasGradients);
    
end

% Compute prediction
if nargout > 2
    [~, pred] = max(solutionProbs);
end

end

